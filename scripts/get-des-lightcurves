#!/usr/bin/env python
"""Get light curves of supernova candidates from DES database.

If no SNIDs are given, all candidates with num_real >= 2 in the SNCAND
table are retrieved. Otherwise, only candidates with the given SNIDs
are retrieved (regardless of whether they have been scanned).

By default, the light curves are retrieved from the SNFORCE table, with
a query on SNCAND_ID. This behavior can be changed using the --table
flag. For the SNOBS table, the query is based on RA and DEC (within a
box of radius 1.08 arcsec). Note that the 'status' fields in the
SNFORCE and SNOBS tables have different meanings.

For the SNFORCE table, when there are multiple rows with the same
EXPNUM (exposure number from the EXPOSURE table), the row with the
latest image_id (from the IMAGE table) is returned; others are
discarded. This assumes that the latests image_id is the 'best'.
"""

import sys
import os
import glob
import math
from datetime import datetime
from optparse import OptionParser
import time
try:
    from collections import OrderedDict as odict
except ImportError:
    odict = dict

import numpy as np
import cx_Oracle
import desdb
try:
    from desdb.desdb import PasswordGetter  # new location in desdb
except ImportError:
    from desdb import PasswordGetter # old location in desdb

def dict_to_array(d):
    """Convert a dictionary of lists (of equal length) to a numpy array."""

    # first convert all lists to 1-d arrays, in order to let numpy
    # figure out the necessary size of the string arrays.
    dtype = []
    for key in d: 
        d[key] = np.array(d[key])
        dtype.append((key, d[key].dtype))
    
    # Initialize ndarray and then fill it.
    firstkey = d.keys()[0]
    result = np.empty(len(d[firstkey]), dtype=dtype)
    for key, col in d.iteritems():
        result[key] = col

    return result

# Writer: csv =============================================================== #
def _write_csv(f, data, meta, **kwargs):
    
    delim = kwargs.get('delim', ' ')
    metachar = kwargs.get('metachar', '@')
    
    if meta is not None:
        for key, val in meta.iteritems():
            f.write('{}{}{}{}\n'.format(metachar, key, delim, str(val)))

    keys = data.dtype.names
    length = len(data)
    
    f.write(delim.join(keys))
    f.write('\n')
    for i in range(length):
        f.write(delim.join([str(data[key][i]) for key in keys]))
        f.write('\n')

# Writer: salt2 ============================================================= #
KEY_TO_SALT2KEY_META = {
    'Z': 'REDSHIFT',              # Not sure if this is used.
    'Z_HELIOCENTRIC': 'Z_HELIO',
    'MAGSYS': 'MagSys',
    'Z_SOURCE': 'z_source'}
KEY_TO_SALT2KEY_COLUMN = {
    'Mjd': 'Date',
    'Time': 'Date',
    'Flux': 'FluxPsf',
    'Fluxpsf': 'FluxPsf',
    'Fluxerr': 'FluxPsferr',
    'Fluxpsferr': 'FluxPsferr',
    'Airmass': 'AirMass',
    'Zp': 'ZP',
    'Zpsys': 'MagSys',
    'Magsys': 'MagSys',
    'Band': 'Filter'}

def _write_salt2(f, data, meta, **kwargs):

    raw = kwargs.get('raw', False)
    pedantic = kwargs.get('pedantic', True)
    
    if meta is not None:
        for key, val in meta.iteritems():
            if not raw:
                key = key.upper()
                key = KEY_TO_SALT2KEY_META.get(key, key)
            f.write('@{} {}\n'.format(key, str(val)))

    keys = data.dtype.names
    length = len(data)

    # Write column names
    keys_as_written = []
    for key in keys:
        if not raw:
            key = key.capitalize()
            key = KEY_TO_SALT2KEY_COLUMN.get(key, key)
        f.write('#{} :\n'.format(key))
        keys_as_written.append(key)
    f.write('#end :\n')

    # Check that necessary fields exist
    if pedantic:
        if not ('Filter' in keys_as_written and 'MagSys' in keys_as_written):
            raise ValueError('photometry data missing required some fields '
                             ': Filter, MagSys')

    # Write the data itself
    for i in range(length):
        f.write(' '.join([str(data[key][i]) for key in keys]))
        f.write('\n')

# Writer: json ============================================================== #
def _write_json(f, data, meta, **kwargs):

    # Build a dictionary of pure-python objects
    output = odict([('meta', meta),
                    ('data', odict())])
    for key in data.dtype.names:
        output['data'][key] = data[key].tolist()
    json.dump(output, f, encoding=sys.getdefaultencoding())
    del output

# All writers =============================================================== #
WRITERS = {'csv': _write_csv,
           'salt2': _write_salt2,
           'json': _write_json}

def write_lc(data, fname, meta=None, fmt='csv', **kwargs):
    """Write light curve data.

    Parameters
    ----------
    data : `~numpy.ndarray` or dict
        Data.
    fname : str
        Filename.
    meta : dict, optional
        A (possibly empty) dictionary of metadata. Default is None.
    fmt : {'csv', 'salt2', 'json'}, optional
        Format of file. Default is 'csv'. 'salt2' is the new format available
        in snfit version >= 2.3.0.
    delim : str, optional
        **[csv only]** Character used to separate entries on a line.
        Default is ' '.
    metachar : str, optional
        **[csv only]** Metadata designator. Default is '@'.
    raw : bool, optional
        **[salt2 only]** By default, the SALT2 writer renames
        some metadata keys and column names in order to comply with what
        snfit expects. Set to True to override this.
        Default is False.
    pedantic : bool, optional
        **[salt2 only]** If True, check that output column names and header
        keys comply with expected formatting, and raise a ValueError if not.
        It is probably a good idea to set to False when raw is True.
        Default is True. 
    """

    if fmt not in WRITERS:
        raise ValueError("Writer not defined for format '{}'. Options: "
                         .format(fmt) + ", ".join(WRITERS.keys()))

    if not isinstance(data, np.ndarray):
        data = dict_to_array(data)

    if meta is None:
        meta = {}

    with open(fname, 'wb') as f:
        WRITERS[fmt](f, data, meta, **kwargs)


# Main ====================================================================== #
def main():

    parser = OptionParser(usage='%prog [options] [SNID ...]',
                          description=__doc__)
    parser.add_option("-n", type="int", default=0,
                      help="Maximum number of light curves to get. Default is"
                      " to get all the light curves.")
    parser.add_option("-a", "--all", default=False, action="store_true",
                      help="Get all candidates, regardless of cand_type. "
                      "Default is to get only candidates that have "
                      "cand_type=0 (indicating current, good).")
    parser.add_option("-t", "--table", default='snforce',
                      help="Table from which to retrieve photometry points. "
                      "Options: snobs, snforce (default: snforce)")
    parser.add_option("-f", "--format", default='csv',
                      help="File format for output. Options: "
                      "csv [default], json, salt2.")
    parser.add_option("-b", "--bandnames", default='g,r,i,z',
                      help="Comma-separated list of names of the DES "
                      "g, r, i, z bands, as they should appear in the "
                      "output files. Example: desg,desr,desi,desz. Default: "
                      "g,r,i,z.")
    parser.add_option("--mindate", default=None,
                      help="Minimum candidate entry_date, format: YYYY-MM-DD")
    parser.add_option("--maxdate", default=None,
                      help="Maximum candidate entry_date, format: YYYY-MM-DD")
    parser.add_option("-o", "--outputdir", default='.',
                      help="Output directory. Default is current directory.")
    parser.add_option("-c", "--clobber", default=False, action='store_true',
                      help="Overwrite (refetch) existing files.")
    parser.add_option("-v", "--verbose", default=False, action='store_true',
                      help="Print query string for all queries.")

    opts, args = parser.parse_args(sys.argv[1:])
    snids = args
    
    outdir = opts.outputdir
    if not os.path.exists(outdir):
        print "DIR must be an existing directory"
        sys.exit(1)
    outdir = outdir.rstrip('/')

    if opts.table not in ['snforce', 'snobs']:
        print "Table must be one of: snforce, snobs"
        sys.exit(1)

    if opts.format not in ['csv', 'snana', 'salt2', 'fits', 'json']:
        print "Format must be one of: csv, snana, salt2."
        sys.exit(1)
    suffix = {'csv': 'dat', 'salt2': 'dat', 'json': 'json'}[opts.format]

    if opts.bandnames != 'g,r,i,z':
        names = opts.bandnames.split(',')
        if len(names) != 4:
            print "bandnames must have 4 comma-separated elements"
            sys.exit(1)
        bandnames = {'g': names[0], 'r': names[1], 'i': names[2],
                     'z': names[3]}
    else:
        bandnames = None

    # Get start time
    t0 = time.time()

    # get database username
    user = PasswordGetter().user

    conn = desdb.connect(dbname='desoper')

    # Get candidate info from database.
    # If specific ids are NOT given, get everything marked as "SN"
    # in the snscan table.
    q = """
        SELECT
            c.snid, c.ra, c.dec, c.cand_type, c.cand_desc, c.numepochs,
            c.numobs, c.num_real, c.num_artifact, c.num_unsure,
            c.num_unscanned, c.entry_date
        FROM
            sncand c
        WHERE
            c.snfake_id=0
        """

    # if specific ids are not given, select all candidates with num_real >= 2.
    # Otherwise, select just the specific SNIDs requested.
    if len(snids) == 0:
        q += "            AND c.num_real >= 2\n"
        if not opts.all:
            q += "            AND c.cand_type=0\n"
    else:
        q += "    AND c.snid in (" + ", ".join(snids) + ")\n"

    # Add date info to query
    if opts.mindate is not None:
        q += "            AND c.entry_date >= date '{}'".format(opts.mindate)
    if opts.maxdate is not None:
        q += "            AND c.entry_date <= date '{}'".format(opts.maxdate)

    q += "        ORDER BY c.snid"

    if opts.verbose:
        print "CANDIDATE QUERY:"
        print q + "\n"

    cands = conn.quick(q)
        
    ncands = len(cands)
    if opts.n > 0:
        maxn = opts.n
    else:
        maxn = ncands

    print '',
    for i in range(maxn):

        cand = cands[i]
        fname = '{}/des{:08d}.{}'.format(outdir, cand['snid'], suffix)
        if not opts.clobber and os.path.exists(fname):
            continue

        print '\rsnid={:8d} ({:6d}/{:6d})'.format(cand['snid'], i+1, ncands),
        sys.stdout.flush()

        if opts.table == 'snforce':
            q = """
            SELECT
                substr(e.object, 22, 2) field, e.band, e.mjd_obs, f.flux,
                f.flux_err, f.status, e.expnum, f.image_id
            FROM
                exposure e, snforce f, image i
            WHERE
                f.sncand_id={:d}
                AND i.id=f.image_id
                AND e.id=i.exposureid
            ORDER BY
                e.expnum, f.image_id
            """.format(cand['snid'])

        elif opts.table == 'snobs':
            q = """
            SELECT
                substr(e.object, 22, 2) field, e.band, e.mjd_obs, o.flux,
                o.flux_err, o.mag, o.status, e.expnum
            FROM
                exposure e, snobs o
            WHERE
                o.ra between {:f} and {:f}
                AND o.dec between {:f} and {:f}
                AND o.exposureid=e.expnum
            ORDER BY
                e.expnum
            """

            boxrad = 1.08 / 3600.
            ra = cand['ra']
            dec = cand['dec']
            dra = boxrad * math.cos(dec * math.pi/180.)
            ddec = boxrad
            q = q.format(ra - dra, ra + dra, dec - ddec, dec + ddec)
 
        if opts.verbose:
            print q
        data = conn.quick(q, array=True)

        # Get just the latest image ID for each exposure (expnum)
        # This counts on the data being ordered by (expnum, image_id).
        if opts.table == 'snforce':
            indicies_to_use = []
            for i in range(1, len(data)):
                if not (data['expnum'][i] == data['expnum'][i-1]):
                    indicies_to_use.append(i-1)
            indicies_to_use.append(len(data)-1)
            data = data[indicies_to_use]

        # Convert band names, if requested.
        if bandnames is None:
            band = data['band']
        if bandnames is not None:
            band = []
            for b in data['band']:
                band.append(bandnames[b])

        # Add zeropoint information
        if opts.table == 'snforce':
            zp = 31.4
        elif opts.table == 'snobs':
            zp = data['mag'] + 2.5 * np.log10(data['flux'])

        finaldata = odict([('time', data['mjd_obs']),
                           ('field', data['field']),
                           ('band', band),
                           ('flux', data['flux']),
                           ('fluxerr', data['flux_err']),
                           ('zp', zp),
                           ('zpsys', 'ab'),
                           ('status', data['status']),
                           ('expnum', data['expnum'])])
        if opts.table == 'snforce':
            finaldata['image_id'] = data['image_id']

        # Create metadata.
        meta = odict()
        meta['query_user'] = user
        meta['query_time'] = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')
        meta['query_utc'] = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%S')
        meta['query_table'] = opts.table
        meta.update(cand)

        # Convert entry_date from datetime object to a string.
        meta['entry_date'] = meta['entry_date'].strftime('%Y-%m-%dT%H:%M:%S')

        # Get host galaxy info from the SNGALS table.
        q = """
            SELECT
                g.photoz as host_photoz, g.photoz_err as host_photoz_err,
                g.specz as host_specz, g.specz_err as host_specz_err,
                g.separation as host_separation
            FROM
                sngals g
            WHERE
                g.snid = {:d}
                AND g.host = 1
            """.format(cand['snid'])
        if opts.verbose:
            print q
        gals = conn.quick(q)
        if len(gals) == 1:
            meta.update(gals[0])
        elif len(gals) == 0:
            meta.update({'host_photoz': None, 'host_photoz_err': None,
                         'host_specz': None, 'host_specz_err': None,
                         'host_separation': None})
        elif len(gals) > 1:
            raise RuntimeError('More than one matching SNGALS entry with '
                               'HOST=1')

        # Turn `None` items into the string 'NULL' for writing to text file.
        for key in meta:
            if meta[key] is None:
                meta[key] = 'NULL'

        write_lc(finaldata, fname, meta=meta, fmt=opts.format,
                 pedantic=False)

    elapsed = time.time() - t0
    print "\nTotal time: {:d}m{:06.3f}s".format(int(elapsed) / 60, elapsed % 60)

if __name__ == '__main__':
    main()
