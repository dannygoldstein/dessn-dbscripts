#!/usr/bin/env python
"""Get light curves of supernova candidates from DES database.

If no SNIDs are given, all candidates with num_real >= 2 in the SNCAND
table are retrieved. Otherwise, only candidates with the given SNIDs
are retrieved (regardless of whether they have been scanned).

By default, the light curves are retrieved from the SNFORCE table, with
a query on SNCAND_ID. This behavior can be changed using the --table
flag. For the SNOBS table, the query is based on RA and DEC (within a
box of radius 1.08 arcsec). Note that the 'status' fields in the
SNFORCE and SNOBS tables have different meanings.

For the SNFORCE table, when there are multiple rows with the same
EXPNUM (exposure number from the EXPOSURE table), the row with the
latest image_id (from the IMAGE table) is returned; others are
discarded. This assumes that the latests image_id is the 'best'.
"""

import sys
import os
import glob
import math
from textwrap import dedent
from datetime import datetime
from optparse import OptionParser
import time
try:
    from collections import OrderedDict as odict
except ImportError:
    odict = dict

import numpy as np
import cx_Oracle
import desdb
try:
    from desdb.desdb import PasswordGetter  # new location in desdb
except ImportError:
    from desdb import PasswordGetter # old location in desdb


def dict_to_array(d):
    """Convert a dictionary of lists (of equal length) to a numpy array."""

    # first convert all lists to 1-d arrays, in order to let numpy
    # figure out the necessary size of the string arrays.
    dtype = []
    for key in d: 
        d[key] = np.array(d[key])
        dtype.append((key, d[key].dtype))
    
    # Initialize ndarray and then fill it.
    firstkey = d.keys()[0]
    result = np.empty(len(d[firstkey]), dtype=dtype)
    for key, col in d.iteritems():
        result[key] = col

    return result

# Writer: csv =============================================================== #
def _write_csv(f, data, meta, **kwargs):
    
    delim = kwargs.get('delim', ' ')
    metachar = kwargs.get('metachar', '@')
    
    if meta is not None:
        for key, val in meta.iteritems():
            f.write('{}{}{}{}\n'.format(metachar, key, delim, str(val)))

    keys = data.dtype.names
    length = len(data)
    
    f.write(delim.join(keys))
    f.write('\n')
    for i in range(length):
        f.write(delim.join([str(data[key][i]) for key in keys]))
        f.write('\n')

# Writer: salt2 ============================================================= #
KEY_TO_SALT2KEY_META = {
    'Z': 'REDSHIFT',              # Not sure if this is used.
    'Z_HELIOCENTRIC': 'Z_HELIO',
    'MAGSYS': 'MagSys',
    'Z_SOURCE': 'z_source'}
KEY_TO_SALT2KEY_COLUMN = {
    'Mjd': 'Date',
    'Time': 'Date',
    'Flux': 'FluxPsf',
    'Fluxpsf': 'FluxPsf',
    'Fluxerr': 'FluxPsferr',
    'Fluxpsferr': 'FluxPsferr',
    'Airmass': 'AirMass',
    'Zp': 'ZP',
    'Zpsys': 'MagSys',
    'Magsys': 'MagSys',
    'Band': 'Filter'}

def _write_salt2(f, data, meta, **kwargs):

    raw = kwargs.get('raw', False)
    pedantic = kwargs.get('pedantic', True)
    
    if meta is not None:
        for key, val in meta.iteritems():
            if not raw:
                key = key.upper()
                key = KEY_TO_SALT2KEY_META.get(key, key)
            f.write('@{0} {1}\n'.format(key, str(val)))

    keys = data.dtype.names
    length = len(data)

    # Write column names
    keys_as_written = []
    for key in keys:
        if not raw:
            key = key.capitalize()
            key = KEY_TO_SALT2KEY_COLUMN.get(key, key)
        f.write('#{0} :\n'.format(key))
        keys_as_written.append(key)
    f.write('#end :\n')

    # Check that necessary fields exist
    if pedantic:
        if not ('Filter' in keys_as_written and 'MagSys' in keys_as_written):
            raise ValueError('photometry data missing required some fields '
                             ': Filter, MagSys')

    # Write the data itself
    for i in range(length):
        f.write(' '.join([str(data[key][i]) for key in keys]))
        f.write('\n')

# Writer: json ============================================================== #
def _write_json(f, data, meta, **kwargs):

    # Build a dictionary of pure-python objects
    output = odict([('meta', meta),
                    ('data', odict())])
    for key in data.dtype.names:
        output['data'][key] = data[key].tolist()
    json.dump(output, f, encoding=sys.getdefaultencoding())
    del output

# All writers =============================================================== #
WRITERS = {'csv': _write_csv,
           'salt2': _write_salt2,
           'json': _write_json}

def write_lc(data, fname, meta=None, fmt='csv', **kwargs):
    """Write light curve data.

    Parameters
    ----------
    data : `~numpy.ndarray` or dict
        Data.
    fname : str
        Filename.
    meta : dict, optional
        A (possibly empty) dictionary of metadata. Default is None.
    fmt : {'csv', 'salt2', 'json'}, optional
        Format of file. Default is 'csv'. 'salt2' is the new format available
        in snfit version >= 2.3.0.
    delim : str, optional
        **[csv only]** Character used to separate entries on a line.
        Default is ' '.
    metachar : str, optional
        **[csv only]** Metadata designator. Default is '@'.
    raw : bool, optional
        **[salt2 only]** By default, the SALT2 writer renames
        some metadata keys and column names in order to comply with what
        snfit expects. Set to True to override this.
        Default is False.
    pedantic : bool, optional
        **[salt2 only]** If True, check that output column names and header
        keys comply with expected formatting, and raise a ValueError if not.
        It is probably a good idea to set to False when raw is True.
        Default is True. 
    """

    if fmt not in WRITERS:
        raise ValueError("Writer not defined for format '{0}'. Options: "
                         .format(fmt) + ", ".join(WRITERS.keys()))

    if not isinstance(data, np.ndarray):
        data = dict_to_array(data)

    if meta is None:
        meta = {}

    with open(fname, 'wb') as f:
        WRITERS[fmt](f, data, meta, **kwargs)


# Main ====================================================================== #
def main():

    parser = OptionParser(usage='%prog [options] [SNID ...]',
                          description=__doc__)
    parser.add_option("-n", type="int", default=-1,
                      help="maximum number of light curves to get (default "
                      "behaviour is to get all 'good' light curves)")
    parser.add_option("-a", "--all", default=False, action="store_true",
                      help="get all candidates, regardless of cand_type "
                      "(default: get only candidates that have "
                      "cand_type=0, indicating current, good)")
    parser.add_option("-t", "--table", default='snforce',
                      help="table from which to retrieve photometry points: "
                      "snobs, snforce (default: snforce)")
    parser.add_option("--fake", default=False, action='store_true',
                      help="get light curves for fake candidates (candidates "
                      "with snfake_id > 0) instead of real ones")
    parser.add_option("--infile", default=None,
                      help="Read SNIDs from this file instead of arguments.")
    parser.add_option("--format", default='csv',
                      help="file format for output: "
                      "csv, json, salt2 (default=csv)")
    parser.add_option("-b", "--bandnames", default='g,r,i,z',
                      help="comma-separated list of names of the DES "
                      "g, r, i, z bands, as they should appear in the "
                      "output files. example: 'desg,desr,desi,desz' default: "
                      "'g,r,i,z'")
    parser.add_option("--mindate", default=None,
                      help="minimum candidate entry_date, format: YYYY-MM-DD")
    parser.add_option("--maxdate", default=None,
                      help="maximum candidate entry_date, format: YYYY-MM-DD")
    parser.add_option("--minfakeid", default=-1, type="int",
                      help="minimum fake_id (only effective with --fake flag)")
    parser.add_option("--maxfakeid", default=-1, type="int",
                      help="maximum fake_id (only effective with --fake flag)")
    parser.add_option("-o", "--outputdir", default='.',
                      help="output directory (default='.')")
    parser.add_option("-c", "--clobber", default=False, action='store_true',
                      help="overwrite (refetch) existing files")
    parser.add_option("-v", "--verbose", default=False, action='store_true',
                      help="print query string for all queries")

    opts, args = parser.parse_args(sys.argv[1:])

    if opts.infile is not None:
        with open(opts.infile, 'r') as f:
            snids = f.read().split()
    else:
        snids = args
    
    outdir = opts.outputdir
    if not os.path.exists(outdir):
        print "DIR must be an existing directory"
        sys.exit(1)
    outdir = outdir.rstrip('/')

    if opts.table not in ['snforce', 'snobs']:
        print "Table must be one of: snforce, snobs"
        sys.exit(1)

    if opts.format not in ['csv', 'salt2', 'json']:
        print "Format must be one of: csv, json, salt2."
        sys.exit(1)
    suffix = {'csv': 'dat', 'salt2': 'dat', 'json': 'json'}[opts.format]

    if opts.bandnames != 'g,r,i,z':
        names = opts.bandnames.split(',')
        if len(names) != 4:
            print "bandnames must have 4 comma-separated elements"
            sys.exit(1)
        bandnames = {'g': names[0], 'r': names[1], 'i': names[2],
                     'z': names[3]}
    else:
        bandnames = None

    # Get start time & db username
    t0 = time.time()
    user = PasswordGetter().user

    # Create a connection to the database
    conn = desdb.connect(dbname='desoper')

    # Query for real candidates:
    if not opts.fake:
        q = dedent(
            """
            SELECT
                c.snid, c.ra, c.dec, c.cand_type, c.cand_desc, c.numepochs,
                c.numobs, c.num_real, c.num_artifact, c.num_unsure,
                c.num_unscanned, c.entry_date, c.snfake_id as fake_id
            FROM
                sncand c
            WHERE
                c.snfake_id=0
            """)
        if len(snids) == 0:
            q += "    AND c.num_real >= 2\n"

    # Query for fake candidates:
    else:
        q = dedent(
            """
            SELECT
                c.snid, c.ra, c.dec, c.cand_type, c.cand_desc, c.numepochs,
                c.numobs, c.num_real, c.num_artifact, c.num_unsure,
                c.num_unscanned, c.entry_date, c.snfake_id as fake_id,
                f.galid as fake_galid, f.z as fake_z,
                f.peakmjd as fake_peakmjd, f.host_angsep as fake_hostsep,
                f.hostmag_i as fake_hostmag_i
            FROM
                sncand c, snfake f
            WHERE
                c.snfake_id>0
                AND c.snfake_id=f.id
            """)
        if opts.minfakeid >= 0:
            q += "    AND c.snfake_id >= {0:d}".format(opts.minfakeid)
        if opts.maxfakeid >= 0:
            q += "    AND c.snfake_id <= {0:d}".format(opts.maxfakeid)

    # Get just certain candidates?
    if len(snids) > 0:
        q += "    AND c.snid in (" + ", ".join(snids) + ")\n"

    # specify cand_type=0 if we didn't request specific candidates:
    if len(snids) == 0 and (not opts.all):
        q += "    AND c.cand_type=0\n"

    # Any specific dates? 
    if opts.mindate is not None:
        q += "    AND c.entry_date >= date '{0}'\n".format(opts.mindate)
    if opts.maxdate is not None:
        q += "    AND c.entry_date <= date '{0}'\n".format(opts.maxdate)

    # Maximum number of candidates to retrieve?
    if opts.n >= 0:
        q += "    AND rownum <= {0:d}\n".format(opts.n)

    q += "ORDER BY c.snid"
    if opts.verbose:
        print 79 * '='
        print "candidate query:"
        print 79 * '='
        print q
        print ""
    cands = conn.quick(q)
    ncands = len(cands)

    print '',
    nempty = 0
    for i in range(len(cands)):

        cand = cands[i]
        fname = '{0}/des{1:08d}.{2}'.format(outdir, cand['snid'], suffix)
        if not opts.clobber and os.path.exists(fname):
            continue

        print '\rsnid ={0:8d} ({1:6d}/{2:6d})'.format(cand['snid'], i+1,
                                                      ncands),
        sys.stdout.flush()

        if opts.table == 'snforce':
            q = """
                SELECT
                    substr(e.object, 22, 2) field, i.ccd as ccdnum, e.band,
                    e.mjd_obs, f.flux, f.flux_err, f.status, e.expnum,
                    f.image_id
                FROM
                    exposure e, snforce f, image i
                WHERE
                     f.sncand_id = {0:d}
                    AND i.id = f.image_id
                    AND e.id = i.exposureid
                ORDER BY
                    e.expnum, f.image_id
                """.format(cand['snid'])

            if opts.fake:
                # For fakes, we want to include a few more columns by
                # matching to other tables. This has to be
                # implemented as a sub-query because we need to match to
                # the snobsinfo table based on *both* expnum and ccdnum
                # and these values come from two different tables
                q = """
                SELECT
                    ph.field, ph.band, ph.ccdnum, ph.mjd_obs, ph.flux,
                    ph.flux_err,
                    ph.status, ph.expnum, ph.image_id,
                    fi.truemag as fake_truemag, oi.chip_zero_point,
                    oi.chip_zero_point_rms
                FROM
                    ({0}) ph
                    left outer join snobsinfo oi
                        on oi.expnum = ph.expnum
                        and oi.ccdnum = ph.ccdnum
                        and oi.tile = 0
                    left outer join snfakeimg fi
                        on fi.expnum = ph.expnum
                        and fi.snfake_id = {1:d}
                """.format(q, cand['fake_id'])

        elif opts.table == 'snobs':
            boxrad = 1.08 / 3600.
            ra = cand['ra']
            dec = cand['dec']
            dra = boxrad * math.cos(dec * math.pi/180.)
            ddec = boxrad
            q = """
            SELECT
                substr(e.object, 22, 2) field, e.band, e.mjd_obs,
                o.flux, o.flux_err, o.mag, o.status, e.expnum
            FROM
                exposure e, snobs o
            WHERE
                o.ra between {0:f} and {1:f}
                AND o.dec between {2:f} and {3:f}
                AND o.exposureid=e.expnum
            ORDER BY
                e.expnum
            """.format(ra - dra, ra + dra, dec - ddec, dec + ddec)
 
        if opts.verbose:
            print ''
            print 79 * '-'
            print dedent(q)

        data = conn.quick(q, array=True)
        #print ''
        #for row in data: print row
        #exit()
        #print data

        if len(data) == 0:
            nempty += 1
            continue

        # Get just the latest image ID for each exposure (expnum)
        # This counts on the data being ordered by (expnum, image_id).
        if opts.table == 'snforce':
            indicies_to_use = []
            for i in range(1, len(data)):
                if not (data['expnum'][i] == data['expnum'][i-1]):
                    indicies_to_use.append(i-1)
            indicies_to_use.append(len(data)-1)
            data = data[indicies_to_use]

        # Convert band names, if requested.
        if bandnames is None:
            band = data['band']
        if bandnames is not None:
            band = []
            for b in data['band']:
                band.append(bandnames[b])

        # Add zeropoint information
        if opts.table == 'snforce':
            zp = 31.4
        elif opts.table == 'snobs':
            zp = data['mag'] + 2.5 * np.log10(data['flux'])

        # TODO: make this more automated (so that fields in 'finaldata' don't
        #       have to be explicitly specified).
        finaldata = odict([('time', data['mjd_obs']),
                           ('field', data['field']),
                           ('band', band),
                           ('ccdnum', data['ccdnum']),
                           ('flux', data['flux']),
                           ('fluxerr', data['flux_err']),
                           ('zp', zp),
                           ('zpsys', 'ab'),
                           ('status', data['status']),
                           ('expnum', data['expnum'])])
        if opts.table == 'snforce':
            finaldata['image_id'] = data['image_id']
        if opts.fake:
            finaldata['fake_truemag'] = data['fake_truemag']
            finaldata['chip_zero_point'] = data['chip_zero_point']
            finaldata['chip_zero_point_rms'] = data['chip_zero_point_rms']

        # Create metadata.
        meta = odict()
        meta['query_user'] = user
        meta['query_time'] = datetime.now().strftime('%Y-%m-%dT%H:%M:%S')
        meta['query_utc'] = datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%S')
        meta['query_table'] = opts.table
        meta.update(cand)

        # Convert entry_date from datetime object to a string.
        meta['entry_date'] = meta['entry_date'].strftime('%Y-%m-%dT%H:%M:%S')

        # Get host galaxy info from the SNGALS table.
        q = """
            SELECT
                g.photoz as host_photoz, g.photoz_err as host_photoz_err,
                g.specz as host_specz, g.specz_err as host_specz_err,
                g.specz_catalog as host_specz_catalog,
                g.separation as host_separation
            FROM
                sngals g
            WHERE
                g.snid = {0:d}
                AND g.host = 1
            """.format(cand['snid'])
        if opts.verbose:
            print dedent(q)
        gals = conn.quick(q)
        if len(gals) == 1:
            meta.update(gals[0])
        elif len(gals) == 0:
            meta.update({'host_photoz': None, 'host_photoz_err': None,
                         'host_specz': None, 'host_specz_err': None,
                         'host_specz_catalog': None,
                         'host_separation': None})
        elif len(gals) > 1:
            raise RuntimeError('More than one matching SNGALS entry with '
                               'HOST=1 for SNID=' + str(cand['snid']))

        # Turn `None` items into the string 'NULL' for writing to text file.
        for key in meta:
            if meta[key] is None:
                if key.startswith('num'):  # hack: None in num columns means 0
                    meta[key] = 0
                else:
                    meta[key] = 'NULL'


        write_lc(finaldata, fname, meta=meta, fmt=opts.format,
                 pedantic=False)

    elapsed = time.time() - t0
    if nempty > 0:
        print "\n{0:d} snids missing photometry were skipped".format(nempty),
    print "\nTotal time: {0:d}m{1:05.2f}s".format(int(elapsed) / 60,
                                                  elapsed % 60)

if __name__ == '__main__':
    main()
